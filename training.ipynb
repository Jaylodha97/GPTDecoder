{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaylodha/.pyenv/versions/3.10.12/envs/gptdecoder/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from data_loader import CustomDataLoader\n",
    "from train import TrainingLoop\n",
    "from eval import Evaluate\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downoad Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/jaylodha/.cache/kagglehub/datasets/mdismielhossenabir/sentiment-analysis/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version of test dataset\n",
    "test_path = kagglehub.dataset_download(\"mdismielhossenabir/sentiment-analysis\")\n",
    "\n",
    "print(\"Path to dataset files:\", test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/jaylodha/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset- this will have the train and val sets\n",
    "path = kagglehub.dataset_download(\"jp797498e/twitter-entity-sentiment-analysis\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data into CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the train and val dfs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{path}/twitter_training.csv\", header = None)\n",
    "val_df = pd.read_csv(f\"{path}/twitter_validation.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0            1         2  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                                   3  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the test df- also apply some post processing to esnure consistent column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"{test_path}/sentiment_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply camel casing\n",
    "test_df['sentiment'] = test_df['sentiment'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.rename(columns={'sentiment': 2}, inplace=True)\n",
    "test_df.rename(columns={'text': 3}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>Platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>morning</td>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>noon</td>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>night</td>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>morning</td>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>noon</td>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day Time of Tweet  \\\n",
       "0  2018      8   18       morning   \n",
       "1  2018      8   18          noon   \n",
       "2  2017      8   18         night   \n",
       "3  2022      6    8       morning   \n",
       "4  2022      6    8          noon   \n",
       "\n",
       "                                                   3         2     Platform  \n",
       "0              What a great day!!! Looks like dream.  Positive    Twitter    \n",
       "1     I feel sorry, I miss you here in the sea beach  Positive    Facebook   \n",
       "2                                     Don't angry me  Negative     Facebook  \n",
       "3  We attend in the class just for listening teac...  Negative    Facebook   \n",
       "4                  Those who want to go, let them go  Negative   Instagram   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data in CustomDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = 3    # Column index for input text\n",
    "label_col = 2   # Column index for labels\n",
    "batch_size = 64 # Batch size for training and validation\n",
    "\n",
    "# Initialize CustomDataLoader\n",
    "custom_loader = CustomDataLoader(train_df, val_df, test_df, text_col, label_col, batch_size)\n",
    "\n",
    "# Get train, validation and test loaders\n",
    "train_loader = custom_loader.get_train_loader(shuffle=True)\n",
    "val_loader = custom_loader.get_val_loader(shuffle=True)\n",
    "test_loader = custom_loader.get_test_loader(shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"vocab_size\": train_loader.dataset.vocab_size,\n",
    "    \"num_embeddings\": 384,\n",
    "    \"block_size\": train_loader.dataset.block_size,\n",
    "    \"num_heads\": 6,\n",
    "    \"num_layers\": 6,\n",
    "    \"output_classes\": len(train_loader.dataset.labels_lookup_dict),\n",
    "    \"dropout\": 0.2,\n",
    "    \"device\": 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"num_epochs\": 100,\n",
    "    \"eval_interval\": 10,\n",
    "    \"eval_iters\": 10,\n",
    "    \"learning_rate\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_path = \"./models_v1\"\n",
    "TrainingLoop(model_params, train_params).train(train_loader, val_loader, save_models_path, resume_path=\"/home/adityadev/GPTDecoder/models_v1/best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Best model- load it from checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate first on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 19:03:42.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36meval\u001b[0m:\u001b[36mload_best_model\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mBest model loaded from /Users/jaylodha/Downloads/best_model_v1.pth\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "val_loader = custom_loader.get_val_loader(shuffle=False)\n",
    "best_model_path = \"/Users/jaylodha/Downloads/best_model_v1.pth\"\n",
    "label_mapping = train_loader.dataset.reverse_labels_lookup_dict\n",
    "\n",
    "report = Evaluate(model_params, best_model_path).evaluate(val_loader, label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant     0.9112    0.8953    0.9032       172\n",
      "    Negative     0.9490    0.9098    0.9290       266\n",
      "     Neutral     0.8684    0.9263    0.8964       285\n",
      "    Positive     0.9081    0.8917    0.8998       277\n",
      "\n",
      "    accuracy                         0.9070      1000\n",
      "   macro avg     0.9092    0.9058    0.9071      1000\n",
      "weighted avg     0.9082    0.9070    0.9072      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 18:58:15.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36meval\u001b[0m:\u001b[36mload_best_model\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mBest model loaded from /Users/jaylodha/Downloads/best_model_v1.pth\u001b[0m\n",
      "/Users/jaylodha/.pyenv/versions/3.10.12/envs/gptdecoder/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jaylodha/.pyenv/versions/3.10.12/envs/gptdecoder/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jaylodha/.pyenv/versions/3.10.12/envs/gptdecoder/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "report = Evaluate(model_params, best_model_path).evaluate(test_loader, label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant     0.0000    0.0000    0.0000         0\n",
      "    Negative     0.4390    0.2687    0.3333       134\n",
      "     Neutral     0.3962    0.3166    0.3520       199\n",
      "    Positive     0.4734    0.5361    0.5028       166\n",
      "\n",
      "    accuracy                         0.3768       499\n",
      "   macro avg     0.3272    0.2803    0.2970       499\n",
      "weighted avg     0.4334    0.3768    0.3971       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer on Raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-08 18:58:39.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36meval\u001b[0m:\u001b[36mload_best_model\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mBest model loaded from /Users/jaylodha/Downloads/best_model_v1.pth\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = Evaluate(model_params, best_model_path).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_on_raw_text(raw_text: str) -> str:\n",
    "\n",
    "  encoded_inp = torch.tensor(train_loader.dataset.encode_text(raw_text), dtype=torch.long, device=model_params.get('device')).unsqueeze(0)\n",
    "  logits = model(encoded_inp)\n",
    "  probs = F.softmax(logits[0], dim=-1)\n",
    "  # Find the index of the largest element\n",
    "  max_index = torch.argmax(probs, dim=1)\n",
    "\n",
    "  label = label_mapping[max_index.item()]\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I'm sad\"\n",
    "infer_on_raw_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some common english words for reference\n",
    "common_words = [\n",
    "    \"happy\", \"sad\", \"angry\", \"excited\", \"joy\", \"love\", \"hate\", \"calm\", \"peace\",\n",
    "    \"extremely\", \"moderately\", \"barely\", \"very\", \"slightly\", \"quick\", \"slow\",\n",
    "    \"fast\", \"intelligent\", \"bright\", \"dull\", \"beautiful\", \"ugly\", \"kind\", \"rude\",\n",
    "    \"strong\", \"weak\", \"powerful\", \"fragile\", \"warm\", \"cold\", \"hot\", \"cool\",\n",
    "    \"rainy\", \"sunny\", \"cloudy\", \"clear\", \"dry\", \"wet\", \"rich\", \"poor\", \"wealthy\",\n",
    "    \"humble\", \"loud\", \"quiet\", \"soft\", \"hard\", \"smooth\", \"rough\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate embeddings from the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(model, unique_words, tokenizer, device, aggregation=\"sum\"):\n",
    "    \"\"\"\n",
    "    Generates consistent-sized embeddings for each unique word using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained GPTDecoder model.\n",
    "        unique_words: List of unique words in the dataset.\n",
    "        tokenizer: Tokenizer used during training.\n",
    "        device: The device (CPU/GPU) to run the model.\n",
    "        aggregation: Aggregation method for multi-token embeddings (\"mean\", \"sum\", \"first\").\n",
    "\n",
    "    Returns:\n",
    "        word_embeddings: Dictionary of word -> embedding.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    word_embeddings = {}\n",
    "\n",
    "    for word in unique_words:\n",
    "        token_ids = torch.tensor([tokenizer.encode(word)], device=device)  # Encode the word to token IDs\n",
    "        position_ids = torch.arange(0, token_ids.size(1), device=device).unsqueeze(0)  # Position IDs\n",
    "\n",
    "        # Pass through embedding layers\n",
    "        token_embedding = model.token_embeddings(token_ids)  # Token embedding\n",
    "        position_embedding = model.positional_embeddings(position_ids)  # Positional embedding\n",
    "        embedding = token_embedding + position_embedding  # Combine token + positional embeddings\n",
    "\n",
    "        # Aggregate embeddings to ensure consistent size\n",
    "        if aggregation == \"mean\":\n",
    "            final_embedding = embedding.mean(dim=1)  # Average pooling across tokens\n",
    "        elif aggregation == \"sum\":\n",
    "            final_embedding = embedding.sum(dim=1)  # Sum pooling across tokens\n",
    "        elif aggregation == \"first\":\n",
    "            final_embedding = embedding[:, 0, :]  # Take the first token's embedding\n",
    "        else:\n",
    "            raise ValueError(\"Invalid aggregation method. Choose from 'mean', 'sum', or 'first'.\")\n",
    "\n",
    "        word_embeddings[word] = final_embedding.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = get_word_embeddings(model, common_words, custom_loader.train_dataset.tokenizer, model_params['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to perform dimensionality reduction- uses PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def reduce_embeddings(word_embeddings, n_components=2):\n",
    "    \"\"\"\n",
    "    Reduces the dimensionality of word embeddings using PCA.\n",
    "\n",
    "    Args:\n",
    "        word_embeddings: Dictionary of word -> embedding.\n",
    "        n_components: Number of dimensions for reduced embeddings (2 or 3).\n",
    "\n",
    "    Returns:\n",
    "        reduced_embeddings: Dictionary of word -> reduced embedding.\n",
    "    \"\"\"\n",
    "    words = list(word_embeddings.keys())\n",
    "    embeddings = list(word_embeddings.values())\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    return {word: reduced_embeddings[idx] for idx, word in enumerate(words)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_word_embeddings = reduce_embeddings(word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to visualise embeddings- saving file as html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "\n",
    "def visualize_embeddings(reduced_embeddings, output_html_path=\"embedding_visualization_v3.html\"):\n",
    "    \"\"\"\n",
    "    Visualizes word embeddings using Plotly and saves the plot as an HTML file.\n",
    "\n",
    "    Args:\n",
    "        reduced_embeddings: Dictionary of word -> reduced embedding.\n",
    "        output_html_path: Path to save the interactive HTML plot.\n",
    "    \"\"\"\n",
    "    words = list(reduced_embeddings.keys())\n",
    "    embeddings = list(reduced_embeddings.values())\n",
    "\n",
    "    # Create a DataFrame for visualization\n",
    "    if len(embeddings[0]) == 2:  # 2D Visualization\n",
    "        df = pd.DataFrame(embeddings, columns=['x', 'y'])\n",
    "    elif len(embeddings[0]) == 3:  # 3D Visualization\n",
    "        df = pd.DataFrame(embeddings, columns=['x', 'y', 'z'])\n",
    "    else:\n",
    "        raise ValueError(\"Embeddings must be reduced to 2 or 3 dimensions.\")\n",
    "\n",
    "    df['word'] = words\n",
    "\n",
    "    # Generate the plot\n",
    "    if len(embeddings[0]) == 2:\n",
    "        fig = px.scatter(df, x='x', y='y', text='word', title='Word Embeddings Visualization (2D)')\n",
    "    else:\n",
    "        fig = px.scatter_3d(df, x='x', y='y', z='z', text='word', title='Word Embeddings Visualization (3D)')\n",
    "\n",
    "    fig.update_traces(textposition='top center')\n",
    "\n",
    "    # Save the plot as an HTML file\n",
    "    pio.write_html(fig, file=output_html_path, auto_open=False)\n",
    "    print(f\"Plot saved as {output_html_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptdecoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
